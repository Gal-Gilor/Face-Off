{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Generation\n",
    "\n",
    "In this project, you'll define and train a DCGAN on a dataset of faces. Your goal is to get a generator network to generate *new* images of faces that look as realistic as possible!\n",
    "\n",
    "The project will be broken down into a series of tasks from **loading in data to defining and training adversarial networks**. At the end of the notebook, you'll be able to visualize the results of your trained Generator to see how it performs; your generated samples should look like fairly realistic faces with small amounts of noise.\n",
    "\n",
    "### Get the Data\n",
    "\n",
    "You'll be using the [CelebFaces Attributes Dataset (CelebA)](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) to train your adversarial networks.\n",
    "\n",
    "This dataset is more complex than the number datasets (like MNIST or SVHN) you've been working with, and so, you should prepare to define deeper networks and train them for a longer time to get good results. It is suggested that you utilize a GPU for training.\n",
    "\n",
    "### Pre-processed Data\n",
    "\n",
    "Since the project's main focus is on building the GANs, we've done *some* of the pre-processing for you. Each of the CelebA images has been cropped to remove parts of the image that don't include a face, then resized down to 64x64x3 NumPy images. Some sample data is show below.\n",
    "\n",
    "<img src='assets/processed_face_data.png' width=60% />\n",
    "\n",
    "> If you are working locally, you can download this data [by clicking here](https://s3.amazonaws.com/video.udacity-data.com/topher/2018/November/5be7eb6f_processed-celeba-small/processed-celeba-small.zip)\n",
    "\n",
    "This is a zip file that you'll need to extract in the home directory of this notebook for further loading and processing. After extracting the data, you should be left with a directory of data `processed_celeba_small/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the CelebA Data\n",
    "\n",
    "The [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) dataset contains over 200,000 celebrity images with annotations. Since you're going to be generating faces, you won't need the annotations, you'll only need the images. Note that these are color images with [3 color channels (RGB)](https://en.wikipedia.org/wiki/Channel_(digital_image)#RGB_Images) each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib as jb\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms as Transforms\n",
    "from torchvision.transforms import Compose\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import init\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "\n",
    "PATH = 'data/'\n",
    "IMAGE_SIZE = 32\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 0\n",
    "EPOCHS = 10\n",
    "PRINT_EVERY = 200\n",
    "GPU = torch.cuda.is_available()\n",
    "\n",
    "# model hyperparameters\n",
    "DISCRIMINATOR_DIM = 32\n",
    "GENERATOR_DIM = 64\n",
    "Z_SIZE = 128 \n",
    "SAMPLE_SIZE = BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define image processing pipeline\n",
    "transforms = Compose([\n",
    "    Transforms.Resize(IMAGE_SIZE),\n",
    "    Transforms.ToTensor(),\n",
    "    Transforms.Normalize(mean=[0.5, 0.5, 0.5], # scales pixel values between -1 and 1\n",
    "                         std=[0.5, 0.5, 0.5]) \n",
    "])\n",
    "\n",
    "# load image datases\n",
    "images = ImageFolder(PATH, transforms)\n",
    "\n",
    "# create data loader\n",
    "real_image_loader = DataLoader(images, BATCH_SIZE, True,  num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# view some of the images\n",
    "images, _ = next(iter(real_image_loader))\n",
    "\n",
    "fig, axes = plt.subplots(2, BATCH_SIZE//2, figsize=(14, 12))\n",
    "\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    \n",
    "    # convert the tensor into a numpy array and change the dimensions\n",
    "    np_image = images[i].numpy()\n",
    "    np_image = np.transpose(np_image, (1, 2, 0))\n",
    "    \n",
    "    # add the image to the grid\n",
    "    ax.imshow(np_image)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: The faces are already cropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Generative Model \n",
    "\n",
    "    1. Discriminator\n",
    "    2. Generator\n",
    "    \n",
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(in_channels, out_channels, kernel_size=4,\n",
    "                          stride=2, padding=1, bias=False, batch_norm=True, dropout=0.25):\n",
    "        '''\n",
    "        Helper function that compiles a Conv2d, BatchNorm, and Dropout layers sequentially\n",
    "        inputs:\n",
    "            in_channels\n",
    "            out_channels\n",
    "            kernel_size\n",
    "            stride\n",
    "            padding\n",
    "            bias\n",
    "            batch_norm\n",
    "            dropout        \n",
    "        '''\n",
    "        layers = []\n",
    "        \n",
    "        # define convolution layer\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, \n",
    "                                   stride=stride, padding=padding, bias=bias)) \n",
    "        \n",
    "        if batch_norm:\n",
    "            # define batch normalization layer\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "        \n",
    "        if dropout:\n",
    "            # add dropout\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, conv_dim=32):\n",
    "        '''\n",
    "        Initialize the Discriminator Module\n",
    "        inputs:\n",
    "            conv_dim: integer, the depth of the first convolutional layer\n",
    "        '''\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.conv_dim = conv_dim\n",
    "        \n",
    "        # define first convolutional layer (BatchNorm2d = False)\n",
    "        self.input = convolution_block(3, conv_dim, batch_norm=False, dropout=0)\n",
    "        \n",
    "        # define additional convolutional layers (BatchNorm2d = True)\n",
    "        self.conv1 = convolution_block(conv_dim, conv_dim*2)\n",
    "        self.conv2 = convolution_block(conv_dim*2, conv_dim*4)\n",
    "       \n",
    "        # define final fully connected layer\n",
    "        self.linear_dim = conv_dim * 4 * 4 * 4\n",
    "        self.outputs = nn.Linear(self.linear_dim, 1)  \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Forward propagation of the neural network and returns the neural network's logits\n",
    "        inputs:\n",
    "            x: The input to the neural network\n",
    "        '''\n",
    "        # convolutional layer (BatchNorm2d = False)\n",
    "        output = F.leaky_relu(self.input(x), 0.2, inplace=True)\n",
    "\n",
    "         # convolutional layers (BatchNorm2d = True)\n",
    "        output = F.leaky_relu(self.conv1(output), 0.2, inplace=True)\n",
    "        output = F.leaky_relu(self.conv2(output), 0.2, inplace=True)\n",
    "        \n",
    "        # flatten\n",
    "        output = output.view(-1, self.linear_dim)\n",
    "    \n",
    "        # final output layer\n",
    "        output = self.outputs(output)        \n",
    "        return output\n",
    "    \n",
    "# test the Discriminator class\n",
    "#tests.test_discriminator(Discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconvolution_block(in_channels, out_channels, kernel_size=4,\n",
    "                          stride=2, padding=1, bias=False, batch_norm=True):\n",
    "    '''\n",
    "    inputs:\n",
    "            in_channels\n",
    "            out_channels\n",
    "            kernel_size\n",
    "            stride\n",
    "            padding\n",
    "            bias\n",
    "            batch_norm        \n",
    "    '''\n",
    "    layers = []\n",
    "\n",
    "    # define deconvolution layer\n",
    "    layers.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, \n",
    "                               stride=stride, padding=padding, bias=bias)) \n",
    "\n",
    "    # define batch normalization layer\n",
    "    if batch_norm:\n",
    "        layers.append(nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    # add activation layer\n",
    "    layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "    return nn.Sequential(*layers) \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, z_size, conv_dim):\n",
    "        '''\n",
    "        Initialize the Generator Module\n",
    "        inputs\n",
    "            z_size: The length of the input latent vector, z\n",
    "            conv_dim: The depth of the inputs to the *last* transpose convolutional layer\n",
    "        '''        \n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.conv_dim = conv_dim\n",
    "        \n",
    "        # dense layer with output dimensions as the discriminatoir's last convolution layer\n",
    "        self.input = nn.Linear(z_size, conv_dim * 4 * 4 * 4)\n",
    "        \n",
    "        # define additional convolutional layers (BatchNorm2d = True)\n",
    "        self.deconv1 = deconvolution_block(conv_dim*4, conv_dim*2)\n",
    "        self.deconv2 = deconvolution_block(conv_dim*2, conv_dim)\n",
    "        \n",
    "        self.outputs = nn.ConvTranspose2d(conv_dim, 3, kernel_size=4, \n",
    "                                       stride=2, padding=1, bias=False)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Forward propagation of the neural network. Returns a Tensor image as output\n",
    "        inputs:\n",
    "            x: The input to the neural network     \n",
    "        '''\n",
    "        \n",
    "        # define feedforward behavior\n",
    "        output = self.input(x)\n",
    "        output = output.view(-1, self.conv_dim*4, 8, 8) # reshape\n",
    "        \n",
    "        # hidden transpose conv layers + relu\n",
    "        output = self.deconv1(output)\n",
    "        output = self.deconv2(output)\n",
    "        \n",
    "        output = torch.tanh(self.outputs(output))\n",
    "        return output    \n",
    "\n",
    "# test the Generator class\n",
    "#tests.test_generator(Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the weights of your networks\n",
    "\n",
    "* Initalizing the Discriminator weights to a normal distribution centered around 0 with a std of 0.02.\n",
    "* Initalizing the Generatpr weights to a Xavier's distribution centered around 0 with a std of 0.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading online I wanted to try xavier for the generator (recommended for tanh activation)\n",
    "# however, this is part of the exercise :(\n",
    "\n",
    "def weights_init_normal(m, init_gain=0.02):\n",
    "    \"\"\"\n",
    "    Applies initial weights to certain layers in a model .\n",
    "    The weights are taken from a normal distribution \n",
    "    with mean = 0, std dev = 0.02.\n",
    "    :param m: A module or layer in a network    \n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    \n",
    "    # intitalize convolution for convolution and linear layers\n",
    "    if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1): \n",
    "        \n",
    "        # set weights to distribute normally around 0 with std of 0.02 \n",
    "        init.normal_(m.weight.data, 0.0, init_gain)\n",
    "        \n",
    "        # set the bias to 0 if the layer class has bias\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "    \n",
    "    # initalize batch normalization layers\n",
    "    elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "            init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_xavier(m, init_gain=0.02):\n",
    "    \"\"\"\n",
    "    Applies initial weights to certain layers in a model .\n",
    "    The weights are taken from a normal distribution \n",
    "    with mean = 0, std dev = 0.02.\n",
    "    :param m: A module or layer in a network    \n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    \n",
    "    # intitalize convolution for convolution and linear layers\n",
    "    if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1): \n",
    "        \n",
    "        # set weights to distribute normally around 0 with std of 0.02 \n",
    "        init.xavier_normal_(m.weight.data, gain=init_gain)\n",
    "        \n",
    "        # set the bias to 0 if the layer class has bias\n",
    "        if hasattr(m, 'bias') and m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "    \n",
    "    # initalize batch normalization layers\n",
    "    elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
    "            init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Build complete network\n",
    "\n",
    "Define your models' hyperparameters and instantiate the discriminator and generator from the classes defined above. Make sure you've passed in the correct input arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciate discriminator and initalize weights\n",
    "D = Discriminator(DISCRIMINATOR_DIM)\n",
    "D.apply(weights_init_normal)\n",
    "\n",
    "# validate discriminator architecture\n",
    "print(D)\n",
    "\n",
    "# instanciate generator\n",
    "G = Generator(Z_SIZE, GENERATOR_DIM)\n",
    "G.apply(weights_init_xavier)\n",
    "\n",
    "# validate generator architecture\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "def build_network(d_conv_dim, g_conv_dim, z_size):\n",
    "    # define discriminator and generator\n",
    "    D = Discriminator(d_conv_dim)\n",
    "    G = Generator(z_size=z_size, conv_dim=g_conv_dim)\n",
    "\n",
    "    # initialize model weights\n",
    "    D.apply(weights_init_normal)\n",
    "    G.apply(weights_init_xavier)\n",
    "\n",
    "    print(D)\n",
    "    print()\n",
    "    print(G)\n",
    "    \n",
    "    return D, G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on GPU\n",
    "\n",
    "Check if you can train on GPU. Here, we'll set this as a boolean variable `train_on_gpu`. Later, you'll be responsible for making sure that \n",
    ">* Models,\n",
    "* Model inputs, and\n",
    "* Loss function arguments\n",
    "\n",
    "Are moved to GPU, where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "# Check for a GPU\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Training on GPU!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Discriminator and Generator Losses\n",
    "\n",
    "Now we need to calculate the losses for both types of adversarial networks.\n",
    "\n",
    "### Discriminator Losses\n",
    "\n",
    "> * For the discriminator, the total loss is the sum of the losses for real and fake images, `d_loss = d_real_loss + d_fake_loss`. \n",
    "* Remember that we want the discriminator to output 1 for real images and 0 for fake images, so we need to set up the losses to reflect that.\n",
    "\n",
    "\n",
    "### Generator Loss\n",
    "\n",
    "The generator loss will look similar only with flipped labels. The generator's goal is to get the discriminator to *think* its generated images are *real*.\n",
    "\n",
    "#### Exercise: Complete real and fake loss functions\n",
    "\n",
    "**You may choose to use either cross entropy or a least squares error loss to complete the following `real_loss` and `fake_loss` functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_loss(D_out, batch_size, gpu, smoothing=False):\n",
    "    '''\n",
    "    Calculates how close discriminator outputs are to being real and return the \"real\" loss.\n",
    "    input:\n",
    "        D_out: discriminator logits\n",
    "    '''\n",
    "    # help prevent discriminator overfitting to real images\n",
    "    labels = torch.ones(batch_size) * 0.9 if smoothing else torch.ones(batch_size)\n",
    "    \n",
    "    if gpu:\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "    # BCEWLL\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # eliminate batch size and compute the loss\n",
    "    return criterion(D_out.squeeze(), labels)\n",
    "\n",
    "def fake_loss(D_out, batch_size, gpu):\n",
    "    '''\n",
    "    Calculates how close discriminator outputs are to being fake and return the \"fake\" loss\n",
    "    input:\n",
    "       D_out: discriminator logits\n",
    "    '''\n",
    "    \n",
    "    # fake image labels\n",
    "    labels = torch.zeros(batch_size)\n",
    "    \n",
    "    if gpu:\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "    # BCEWLL\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # eliminate batch size and compute the loss\n",
    "    return criterion(D_out.squeeze(), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "Define optimizers for your models with appropriate hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "b1 = 0.5\n",
    "b2 = 0.999 \n",
    "\n",
    "# Create optimizers for the discriminator D and generator G\n",
    "discriminator_optim = optim.Adam(D.parameters(), lr=5e-5, betas=(b1, b2)) # used in the DCGAN paper\n",
    "generator_optim = optim.Adam(G.parameters(), lr=5e-5, betas=(b1, b2)) # used in the DCGAN paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training\n",
    "\n",
    "Training will involve alternating between training the discriminator and the generator. You'll use your functions `real_loss` and `fake_loss` to help you calculate the discriminator losses.\n",
    "\n",
    "* You should train the discriminator by alternating on real and fake images\n",
    "* Then the generator, which tries to trick the discriminator and should have an opposing loss function\n",
    "\n",
    "\n",
    "#### Saving Samples\n",
    "\n",
    "You've been given some code to print out some loss statistics and save some generated \"fake\" samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Complete the training function\n",
    "\n",
    "Keep in mind that, if you've moved your models to GPU, you'll also have to move any model inputs to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(discriminator, optimizer, inputs, gpu, batch_size, real=True, generator=None):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    if real:\n",
    "        discriminator_output = discriminator(inputs)\n",
    "        discriminator_loss = real_loss(discriminator_output, batch_size, gpu, smoothing=True)\n",
    "        \n",
    "    else:\n",
    "        # generate fake images\n",
    "        fake_images = generator(inputs) \n",
    "        \n",
    "        # train on fake images\n",
    "        discriminator_output = discriminator(fake_images)\n",
    "        discriminator_loss = fake_loss(discriminator_output, batch_size, gpu)\n",
    "        \n",
    "    return discriminator_loss\n",
    "\n",
    "def train_generator(generator, discriminator, optimizer, inputs, gpu, batch_size):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    # generate fake images\n",
    "    fake_images = generator(inputs) \n",
    "\n",
    "    # train on fake images\n",
    "    generator_output = discriminator(fake_images)\n",
    "    generator_loss = real_loss(generator_output, batch_size, gpu, smoothing=False)\n",
    "    \n",
    "    return generator_loss\n",
    "    \n",
    "    \n",
    "def generate_sample_images(sample_size, z_size):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    # get some fixed data for sampling. these are images that are held\n",
    "    # constant throughout training, and allow us to inspect the model's performance\n",
    "    sample = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
    "    sample = torch.from_numpy(sample).float()\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = []\n",
    "\n",
    "if GPU:\n",
    "    D.cuda()\n",
    "    G.cuda()\n",
    "    \n",
    "for epoch in range(2):\n",
    "    for n, (real_images, _) in enumerate(real_image_loader):\n",
    "        \n",
    "        # training mode\n",
    "        G.train() \n",
    "        D.train() \n",
    "        \n",
    "        # TRAIN DISCRIMINATOR\n",
    "        \n",
    "        # clear gradients\n",
    "        discriminator_optim.zero_grad()\n",
    "        \n",
    "        # train the discriminator on real images\n",
    "        if GPU:\n",
    "            real_images = real_images.cuda()\n",
    "        \n",
    "        discriminator_real_image_loss = train_discriminator(D, discriminator_optim, \n",
    "                                                            real_images, GPU, BATCH_SIZE)\n",
    "        \n",
    "        \n",
    "        # train the discriminator on fake images\n",
    "        fakes = generate_sample_images(BATCH_SIZE, Z_SIZE)\n",
    "        \n",
    "        if GPU:\n",
    "            fakes = fakes.cuda()\n",
    "            \n",
    "        discriminator_fake_image_loss = train_discriminator(D, discriminator_optim, \n",
    "                                                            fakes, GPU, BATCH_SIZE,\n",
    "                                                            real=False, generator=G)\n",
    "        \n",
    "        # compute discriminator total loss and perform backprop\n",
    "        discriminator_loss = discriminator_real_image_loss + discriminator_fake_image_loss\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optim.step()\n",
    "        \n",
    "        # TRAIN GENERATOR \n",
    "        \n",
    "        # clear gradients\n",
    "        generator_optim.zero_grad()\n",
    "        \n",
    "        # train the generator on adverserial loss\n",
    "        fakes = generate_sample_images(BATCH_SIZE, Z_SIZE)\n",
    "        \n",
    "        if GPU:\n",
    "            fakes = fakes.cuda()\n",
    "            \n",
    "        # compute generator loss\n",
    "        generator_loss = train_generator(G, D, generator_optim, fakes, GPU, BATCH_SIZE)\n",
    "        generator_loss.backward()\n",
    "        generator_optim.step()\n",
    "        \n",
    "        \n",
    "        # print some loss stats\n",
    "        if n % PRINT_EVERY == 0:\n",
    "            \n",
    "            # note loss\n",
    "            total_loss.append((discriminator_loss.item(), generator_loss.item()))\n",
    "            \n",
    "            # print discriminator and generator loss\n",
    "            print(f'Epoch: {epoch+1}/{EPOCHS} || D Loss: {discriminator_loss} || G Loss: {generator_loss}')\n",
    "            print(fakes[0].size())\n",
    "        # save model weights\n",
    "                \n",
    "            \n",
    "# clear GPU memory\n",
    "if GPU:\n",
    "    D.cpu()\n",
    "    G.cpu()\n",
    "    real_images = real_images.cpu()\n",
    "    fakes = fakes.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate geneerator performance    \n",
    "\n",
    "G.eval() \n",
    "with torch.no_grad():\n",
    "    constant_sample = generate_sample_images(SAMPLE_SIZE, Z_SIZE)\n",
    "    samples_z = G(constant_sample)\n",
    "    \n",
    "# view samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(D, G, n_epochs, train_on_gpu, print_every=50):\n",
    "    '''Trains adversarial networks for some number of epochs\n",
    "       param, D: the discriminator network\n",
    "       param, G: the generator network\n",
    "       param, n_epochs: number of epochs to train for\n",
    "       param, print_every: when to print and record the models' losses\n",
    "       return: D and G losses'''\n",
    "    \n",
    "    # move models to GPU\n",
    "    if train_on_gpu:\n",
    "        D.cuda()\n",
    "        G.cuda()\n",
    "\n",
    "    # keep track of loss and generated, \"fake\" samples\n",
    "    samples = []\n",
    "    losses = []\n",
    "\n",
    "    # Get some fixed data for sampling. These are images that are held\n",
    "    # constant throughout training, and allow us to inspect the model's performance\n",
    "    sample_size=16\n",
    "    fixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
    "    fixed_z = torch.from_numpy(fixed_z).float()\n",
    "    \n",
    "    # move z to GPU if available\n",
    "    if train_on_gpu:\n",
    "        fixed_z = fixed_z.cuda()\n",
    "\n",
    "    # epoch training loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # batch training loop\n",
    "        for batch_i, (real_images, _) in enumerate(real_image_loader):\n",
    "\n",
    "            batch_size = real_images.size(0)\n",
    "            #real_images = scale(real_images)\n",
    "            \n",
    "            # DISCRIMINATOR TRAIN\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            # 1.1 Train the discriminator on real images\n",
    "            real_images = real_images.cuda() if train_on_gpu else real_images\n",
    "            disc_real_train = D(real_images)\n",
    "            d_real_loss = real_loss(disc_real_train, batch_size, train_on_gpu, smoothing=True)\n",
    "            \n",
    "            # 1.2 Train the discriminator on fake images\n",
    "            fake_arr = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
    "            fake_arr = torch.from_numpy(fake_arr).float()\n",
    "            fake_arr = fake_arr.cuda() if train_on_gpu else fake_arr\n",
    "            fake_image = G(fake_arr) \n",
    "            \n",
    "            disc_fake_train = D(fake_image)\n",
    "            d_fake_loss = fake_loss(disc_fake_train, batch_size, train_on_gpu)\n",
    "            \n",
    "            # compute discriminator total loss and perform backprop\n",
    "            d_loss = d_real_loss + d_fake_loss\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            \n",
    "            # GENERATOR TRAIN\n",
    "            g_optimizer.zero_grad()\n",
    "            \n",
    "            # 2. Train the generator with an adversarial loss\n",
    "            fake_arr = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
    "            fake_arr = torch.from_numpy(fake_arr).float()\n",
    "            fake_arr = fake_arr.cuda() if train_on_gpu else fake_arr\n",
    "            fake_image = G(fake_arr) \n",
    "            \n",
    "            # compute loss on fake images and real images label\n",
    "            disc_fake_train = D(fake_image)\n",
    "            \n",
    "            # compute generator loss and perform backprop\n",
    "            g_loss = real_loss(disc_fake_train, batch_size, train_on_gpu, smoothing=False)\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            # Print some loss stats\n",
    "            if batch_i % print_every == 0:\n",
    "                # append discriminator loss and generator loss\n",
    "                losses.append((d_loss.item(), g_loss.item()))\n",
    "                # print discriminator and generator loss\n",
    "                print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
    "                        epoch+1, n_epochs, d_loss.item(), g_loss.item()))\n",
    "\n",
    "\n",
    "        ## AFTER EACH EPOCH##    \n",
    "        # this code assumes your generator is named G, feel free to change the name\n",
    "        # generate and save sample, fake images\n",
    "        G.eval() # for generating samples\n",
    "        with torch.no_grad():\n",
    "            samples_z = G(fixed_z)\n",
    "            samples_z = samples_z.detach().cpu()\n",
    "            samples.append(samples_z)\n",
    "        G.train() # back to training mode\n",
    "\n",
    "    # Save training generator samples\n",
    "    with open('train_samples.pkl', 'wb') as f:\n",
    "        pkl.dump(samples, f)\n",
    "    \n",
    "    # unload gpu memory\n",
    "    if train_on_gpu:\n",
    "        D.cpu()\n",
    "        G.cpu()\n",
    "        real_images = real_images.cpu()\n",
    "        fake_image = fake_image.cpu()\n",
    "    \n",
    "    # finally return losses\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your number of training epochs and train your GAN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set number of epochs \n",
    "n_epochs = 15\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# call training function\n",
    "losses = train(D, G, n_epochs, train_on_gpu, print_every=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training loss\n",
    "\n",
    "Plot the training losses for the generator and discriminator, recorded after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "losses = np.array(losses)\n",
    "plt.plot(losses.T[0], label='Discriminator', alpha=0.5)\n",
    "plt.plot(losses.T[1], label='Generator', alpha=0.5)\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Generator samples from training\n",
    "\n",
    "View samples of images from the generator, and answer a question about the strengths and weaknesses of your trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for viewing a list of passed in sample images\n",
    "def view_samples(epoch, samples):\n",
    "    fig, axes = plt.subplots(figsize=(16,4), nrows=2, ncols=8, sharey=True, sharex=True)\n",
    "    for ax, img in zip(axes.flatten(), samples[epoch]):\n",
    "        img = img.detach().cpu().numpy()\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        img = ((img + 1)*255 / (2)).astype(np.uint8)\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        im = ax.imshow(img.reshape((64,64,3)))\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load samples from generator, taken while training\n",
    "with open('train_samples.pkl', 'rb') as f:\n",
    "    samples = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = view_samples(-1, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What do you notice about your generated samples, and how might you improve this model?\n",
    "When you answer this question, consider the following factors:\n",
    "* The dataset is biased; it is made of \"celebrity\" faces that are mostly white\n",
    "* Model size; larger models have the opportunity to learn more features in a data feature space\n",
    "* Optimization strategy; optimizers and number of epochs affect your final result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: What do you notice about your generated samples, and how might you improve this model?\n",
    "Not surprisingly, the model creates low-resolution images. Nevertheless, the generated samples look decent (granted, some of them seem like Frankenstein). Unfortunately, more extended training doesn't improve the pictures. There are 32k images in our dataset. This number is several orders of magnitudes smaller than the number of people that exist (or existed). Because people of color weren't well represented, I expected to generate more realistic-looking faces with light-colored complexion. Also, I suspect that the model would not create as many faces with colors.\n",
    "\n",
    "To improve the generative model, I would probably need to restrain the discriminator even more than I have. So, I started with a 0.9 smoothing factor and lowered it to 0.75. Furthermore, I noticed that the discriminator learns a lot faster than the generator and that training the model for more time did not improve the results. \n",
    "\n",
    "To prevent the discriminator from overfitting and improve the generative model outputs, I would:\n",
    "\n",
    "1. Remove one of the convolutional layers.\n",
    "2. Add noise to the authentic images. I would likely try to implement a \"noise decay\" strategy. Meaning, I would add more noise to the pictures at the beginning of the training and reduce the amount of noise as the training process continues.\n",
    "\n",
    "Additionally, I would try changing the generator's weight initialization strategy to Xavier's initialization. I read online it yielded better results than the normal distribution strategy when using the tanh activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as \"dlnd_face_generation.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\". Include the \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
